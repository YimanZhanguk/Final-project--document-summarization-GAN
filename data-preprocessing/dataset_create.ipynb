{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset create"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### original dataset：\n",
    "https://ciir.cs.umass.edu/downloads/nfL6/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## load original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mydata = json.load(open('/Users/zhangyiman/Desktop/nfL6.json','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "questions = []\n",
    "bestAnswers = []\n",
    "NotBestAnswers = []\n",
    "main_categorys = []\n",
    "q_id = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for q_a in mydata:\n",
    "    questions.append(q_a['question'])\n",
    "    bestAnswers.append(q_a['answer'])\n",
    "    NotBestAnswers.append(q_a['nbestanswers'])\n",
    "    main_categorys.append(q_a['main_category'])\n",
    "    q_id.append(q_a['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why did the U.S Invade Iraq ?'"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A small group of politicians believed strongly that the fact that Saddam Hussien remained in power after the first Gulf War was a signal of weakness to the rest of the world, one that invited attacks and terrorism. Shortly after taking power with George Bush in 2000 and after the attack on 9/11, they were able to use the terrorist attacks to justify war with Iraq on this basis and exaggerated threats of the development of weapons of mass destruction. The military strength of the U.S. and the brutality of Saddam's regime led them to imagine that the military and political victory would be relatively easy.\""
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestAnswers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't have an article, but I was listening to NPR last night, and the commentator was saying the evacuation was really bungled due to an organization and communication problem. No one took charge and said, hey I'm running the show, get 2000 buses and send them down, because no one felt they were in charge. FEMA, State & local police, National Guard, all were not sure what the other guys were doing and so waited for overall direction, which never really came.\""
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestAnswers[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"A small group of politicians believed strongly that the fact that Saddam Hussien remained in power after the first Gulf War was a signal of weakness to the rest of the world, one that invited attacks and terrorism. Shortly after taking power with George Bush in 2000 and after the attack on 9/11, they were able to use the terrorist attacks to justify war with Iraq on this basis and exaggerated threats of the development of weapons of mass destruction. The military strength of the U.S. and the brutality of Saddam's regime led them to imagine that the military and political victory would be relatively easy.\",\n",
       " 'Because there is a lot of oil in Iraq.',\n",
       " 'It is tempting to say that the US invaded Iraq because it has lots of oil, but the US is not a country in a deep economic problem that capturing other country’s oil is an actual need for survival. It is more likely that the Iraq invading Kuwait scenario would fall under that assumption.. I think that the US government has come to a conclusion that we are on the verge of a war of religions, or more likely ideologies. It would be presumptuous to try and determent a one cause to the coming war. . I think that the world wide spread of the media with its many forms (Cable, Satellite, Internet, etc.)  have pushed the Moslem regimes to the extreme, fearing that secularity and democratic influence is penetrating their country and will result in an up raising against them. One of the best way to maintain the power that you have and even gain more of it, is by hatred. When the common man is occupied hating an outside enemy, its hatred is kept out side the county and would not be directed towards the regime. . So- I believe that the US understands that the fanatic Moslem regimes have already started a war on the democratic world and now is the time to try a fight it.. . So why invade Iraq? Because it is a huge, week Moslem country that thought to be easy to defeat. . This is exactly the same reason why Afghanistan was first and Syria is next in line.',\n",
       " 'I think Yuval is pretty spot on. It\\'s a proving ground and a focal point for terror activity that\\'s not on American soil. And, because no one liked Saddam Hussein, no other countries (even in the Middle East) were about to rise up and join his side.. . Rabid speculation: now the Pentagon has a model that says it takes ~5 years, ~$200B and ~2,000 casualties to \"rebuild\" a dictatorship into a democracy. Who\\'s next on the list?']"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NotBestAnswers[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import re, math\\nfrom collections import Counter\\n\\nWORD = re.compile(r'\\\\w+')\\n\\ndef get_cosine(vec1, vec2):\\n    intersection = set(vec1.keys()) & set(vec2.keys())\\n    numerator = sum([vec1[x] * vec2[x] for x in intersection])\\n\\n    sum1 = sum([vec1[x]**2 for x in vec1.keys()])\\n    sum2 = sum([vec2[x]**2 for x in vec2.keys()])\\n    denominator = math.sqrt(sum1) * math.sqrt(sum2)\\n\\n    if not denominator:\\n        return 0.0\\n    else:\\n        return float(numerator) / denominator\\n\\ndef text_to_vector(text):\\n    words = WORD.findall(text)\\n    return Counter(words)\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import re, math\n",
    "from collections import Counter\n",
    "\n",
    "WORD = re.compile(r'\\w+')\n",
    "\n",
    "def get_cosine(vec1, vec2):\n",
    "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "\n",
    "    sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
    "    sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
    "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "\n",
    "    if not denominator:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(numerator) / denominator\n",
    "\n",
    "def text_to_vector(text):\n",
    "    words = WORD.findall(text)\n",
    "    return Counter(words)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# sentences candidate\\n\\nquery_id = []\\nquery = []\\ncategory = []\\nsentence_id = []\\nsentence = []\\nwhether_groundTruth = []\\nsimilar_to_which = []\\n\\nfor j in range (0,len(NotBestAnswers)):\\n    # for every question, \\n    sentence_candidate = []\\n    Ground_Truth_sentence = []\\n    \\n    # there are len_sen answers for this question\\n    len_sen = len(NotBestAnswers[j])\\n    for a in range(0,len_sen):\\n        str = NotBestAnswers[j][a]\\n        str_split = str.split('. ')\\n        # reduce if sentence is null\\n        for i in range(0,len(str_split)):\\n            if len(str_split[i])>=2:\\n                sentence_candidate.append(str_split[i])\\n                \\n    #Ground Truth sentences\\n    str = bestAnswers[j]\\n    str_split = str.split('. ')\\n    for i in range(0,len(str_split)):\\n        Ground_Truth_sentence.append(str_split[i])\\n        \\n    #Whether ground truth\\n    for i in range(0,len(sentence_candidate)):\\n        if sentence_candidate[i] not in Ground_Truth_sentence:\\n            Ground_Truth = 0\\n        else:\\n            Ground_Truth = 1\\n        query_id.append(j)\\n        query.append(questions[j])\\n        category.append(main_categorys[j])\\n        sentence_id.append(i)\\n        sentence.append(sentence_candidate[i])\\n        whether_groundTruth.append(Ground_Truth)\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# sentences candidate\n",
    "\n",
    "query_id = []\n",
    "query = []\n",
    "category = []\n",
    "sentence_id = []\n",
    "sentence = []\n",
    "whether_groundTruth = []\n",
    "similar_to_which = []\n",
    "\n",
    "for j in range (0,len(NotBestAnswers)):\n",
    "    # for every question, \n",
    "    sentence_candidate = []\n",
    "    Ground_Truth_sentence = []\n",
    "    \n",
    "    # there are len_sen answers for this question\n",
    "    len_sen = len(NotBestAnswers[j])\n",
    "    for a in range(0,len_sen):\n",
    "        str = NotBestAnswers[j][a]\n",
    "        str_split = str.split('. ')\n",
    "        # reduce if sentence is null\n",
    "        for i in range(0,len(str_split)):\n",
    "            if len(str_split[i])>=2:\n",
    "                sentence_candidate.append(str_split[i])\n",
    "                \n",
    "    #Ground Truth sentences\n",
    "    str = bestAnswers[j]\n",
    "    str_split = str.split('. ')\n",
    "    for i in range(0,len(str_split)):\n",
    "        Ground_Truth_sentence.append(str_split[i])\n",
    "        \n",
    "    #Whether ground truth\n",
    "    for i in range(0,len(sentence_candidate)):\n",
    "        if sentence_candidate[i] not in Ground_Truth_sentence:\n",
    "            Ground_Truth = 0\n",
    "        else:\n",
    "            Ground_Truth = 1\n",
    "        query_id.append(j)\n",
    "        query.append(questions[j])\n",
    "        category.append(main_categorys[j])\n",
    "        sentence_id.append(i)\n",
    "        sentence.append(sentence_candidate[i])\n",
    "        whether_groundTruth.append(Ground_Truth)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'similar_to_which = []'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''similar_to_which = []'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"sentence = []\\nsimilar_to_which = []\\n\\nfor j in range (0,len(NotBestAnswers)):\\n    # for every question, \\n    sentence_candidate = []\\n    Ground_Truth_sentence = []\\n    \\n    # there are len_sen answers for this question\\n    len_sen = len(NotBestAnswers[j])\\n    for a in range(0,len_sen):\\n        str = NotBestAnswers[j][a]\\n        str_split = str.split('. ')\\n        # reduce if sentence is null\\n        for i in range(0,len(str_split)):\\n            if len(str_split[i])>=2:\\n                sentence_candidate.append(str_split[i])\\n                \\n    #Ground Truth sentences\\n    str = bestAnswers[j]\\n    str_split = str.split('. ')\\n    for i in range(0,len(str_split)):\\n        Ground_Truth_sentence.append(str_split[i])\\n        \\n    #Similar to which sentence\\n    for i in range(0,len(sentence_candidate)):\\n        hypothese = sentence_candidate[i]\\n        text1 = hypothese\\n        vector1 = text_to_vector(text1)\\n        max_score = 0.5\\n        similar_sentence = ''\\n        for n in range(0,len(Ground_Truth_sentence)):\\n            reference = Ground_Truth_sentence[n]\\n            text2 = reference\\n            vector2 = text_to_vector(text2)\\n            cosine = get_cosine(vector1, vector2)\\n            if cosine > max_score:\\n                max_score = cosine\\n                similar_sentence = reference\\n        if max_score == 0.5:\\n            random_number = random.randint(0,len(Ground_Truth_sentence)-1)\\n            similar_sentence = Ground_Truth_sentence[random_number]\\n            \\n        similar_to_which.append(similar_sentence)\\n        sentence.append(sentence_candidate[i])\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''sentence = []\n",
    "similar_to_which = []\n",
    "\n",
    "for j in range (0,len(NotBestAnswers)):\n",
    "    # for every question, \n",
    "    sentence_candidate = []\n",
    "    Ground_Truth_sentence = []\n",
    "    \n",
    "    # there are len_sen answers for this question\n",
    "    len_sen = len(NotBestAnswers[j])\n",
    "    for a in range(0,len_sen):\n",
    "        str = NotBestAnswers[j][a]\n",
    "        str_split = str.split('. ')\n",
    "        # reduce if sentence is null\n",
    "        for i in range(0,len(str_split)):\n",
    "            if len(str_split[i])>=2:\n",
    "                sentence_candidate.append(str_split[i])\n",
    "                \n",
    "    #Ground Truth sentences\n",
    "    str = bestAnswers[j]\n",
    "    str_split = str.split('. ')\n",
    "    for i in range(0,len(str_split)):\n",
    "        Ground_Truth_sentence.append(str_split[i])\n",
    "        \n",
    "    #Similar to which sentence\n",
    "    for i in range(0,len(sentence_candidate)):\n",
    "        hypothese = sentence_candidate[i]\n",
    "        text1 = hypothese\n",
    "        vector1 = text_to_vector(text1)\n",
    "        max_score = 0.5\n",
    "        similar_sentence = ''\n",
    "        for n in range(0,len(Ground_Truth_sentence)):\n",
    "            reference = Ground_Truth_sentence[n]\n",
    "            text2 = reference\n",
    "            vector2 = text_to_vector(text2)\n",
    "            cosine = get_cosine(vector1, vector2)\n",
    "            if cosine > max_score:\n",
    "                max_score = cosine\n",
    "                similar_sentence = reference\n",
    "        if max_score == 0.5:\n",
    "            random_number = random.randint(0,len(Ground_Truth_sentence)-1)\n",
    "            similar_sentence = Ground_Truth_sentence[random_number]\n",
    "            \n",
    "        similar_to_which.append(similar_sentence)\n",
    "        sentence.append(sentence_candidate[i])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import csv\\n\\nwith open(\\'create_QA.csv\\', \\'w\\') as datacsv:\\n    writer = csv.writer(datacsv,dialect=(\"excel\"))\\n    writer.writerow([\\'query_id\\',\\'query\\',\\'sentence_id\\',\\'sentence\\',\\'whether_groundTruth\\',\\'similar_to_which\\'])\\n    for i in range(0,len(query_id)):\\n        writer.writerow([query_id[i],query[i],sentence_id[i],sentence[i],whether_groundTruth[i],similar_to_which[i]])'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import csv\n",
    "\n",
    "with open('create_QA.csv', 'w') as datacsv:\n",
    "    writer = csv.writer(datacsv,dialect=(\"excel\"))\n",
    "    writer.writerow(['query_id','query','sentence_id','sentence','whether_groundTruth','similar_to_which'])\n",
    "    for i in range(0,len(query_id)):\n",
    "        writer.writerow([query_id[i],query[i],sentence_id[i],sentence[i],whether_groundTruth[i],similar_to_which[i]])'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "from sumy.parsers.html import HtmlParser\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer as Summarizer\n",
    "from sumy.nlp.stemmers import Stemmer\n",
    "from sumy.utils import get_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentence = []\n",
    "for j in range (0,len(bestAnswers)):\n",
    "    # for every question, \n",
    "    sentence_candidate = []\n",
    "    \n",
    "    # there are len_sen answers for this question\n",
    "    len_sen = len(bestAnswers[j])\n",
    "    str = bestAnswers[j]\n",
    "    str_split = str.split('. ')\n",
    "    # reduce if sentence is null\n",
    "    for i in range(0,len(str_split)):\n",
    "        if len(str_split[i])>=2:\n",
    "            sentence_candidate.append(str_split[i])\n",
    "    sentence.append(sentence_candidate)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87362"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87362"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['China is more concerned with threat from US or Japan than North Korea',\n",
       " ' Besides, both India and Pakistan have nuclear weapon already and are close to China as well',\n",
       " \" But it's hardly a big concern for China people.\"]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LANGUAGE = \"english\"\n",
    "SENTENCES_COUNT = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing:\n",
      "0\n",
      "processing:\n",
      "20000\n",
      "processing:\n",
      "40000\n",
      "processing:\n",
      "60000\n",
      "processing:\n",
      "80000\n"
     ]
    }
   ],
   "source": [
    "hypo = []\n",
    "for i in range(0,len(questions)):\n",
    "    if i%20000 ==0:\n",
    "        print(\"processing:\")\n",
    "        print(i)\n",
    "    with open('document.txt','w') as f:\n",
    "            for j in range(0,len(sentence[i])):\n",
    "                f.write(sentence[i][j])\n",
    "                f.write('\\n')\n",
    "    f.close()\n",
    "        \n",
    "    parser = PlaintextParser.from_file(\"document.txt\", Tokenizer(LANGUAGE))\n",
    "    stemmer = Stemmer(LANGUAGE)\n",
    "\n",
    "    summarizer = Summarizer(stemmer)\n",
    "    summarizer.stop_words = get_stop_words(LANGUAGE)   \n",
    "      \n",
    "    evaluated_sentences = (summarizer(parser.document, SENTENCES_COUNT))\n",
    "    hypothesis = ' '\n",
    "    if len(evaluated_sentences)>0:\n",
    "            for i in range(0,1):\n",
    "                str_111 = ' '\n",
    "                for i in range(0,len(evaluated_sentences[0].words)):\n",
    "                    str_111 = str_111 + evaluated_sentences[0].words[i]\n",
    "                    str_111 = str_111 + ' '\n",
    "                hypothesis = hypothesis + str_111\n",
    "            reference = bestAnswers[query_id_flag]\n",
    "            hypo.append(hypothesis)\n",
    "    else:\n",
    "            hypo.append('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87362"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hypo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87362"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87362"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(NotBestAnswers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Yout Issues\" are things that impact all youth..like drugs, sex, smoking, or even the immagration issue.  Usually our youth can see answers that we adults have closed our eyes to.  Almost any issue you hear students talking about at school could be considered a \"youth issue\".'"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestAnswers[50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  Crunches and lots of exercise Ya got ta move it to lose it '"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypo[20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are two kinds of primary colors:  those you get by combining light (these are called \"additive\") and those you get by mixing pigments (these are called \"subtractive\").  As many computer users know, the additive colors are red, green, and blue.  Traditionally, the subtractive colors were red, yellow, and blue.  But more technically, they are magenta, yellow, and cyan (a kind of blue).'"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NotBestAnswers[10][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Question = []\n",
    "Question_id = []\n",
    "Target_answer = []\n",
    "Document = []\n",
    "for i in range(0,len(hypo)):\n",
    "    str = hypo[i]\n",
    "    str_split = str.split(' ')\n",
    "    if len(str_split)<20 and len(str_split)>5 :\n",
    "        Question_id.append(q_id[i])\n",
    "        Question.append(questions[i])\n",
    "        Target_answer.append(hypo[i])\n",
    "        try:\n",
    "            strr_d = ''\n",
    "            for j in range(0,len(NotBestAnswers)):\n",
    "                strr_d = strr_d + NotBestAnswers[i][j]\n",
    "                strr_d = strr_d + ' '\n",
    "            str = strr_d\n",
    "            str_document = str.split(' ')\n",
    "            str_d = ''\n",
    "            for j in range(0,len(str_document)):\n",
    "                str_d = str_d + str_document[j]\n",
    "                str_d = str_d = ' '\n",
    "            Document.append(str_d)\n",
    "        except:\n",
    "            Document.append(bestAnswers[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21613"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Target_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21613"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Question_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-220-8626df332216>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-220-8626df332216>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    for i in range(0,len(Question_id)):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('first_gan.csv', 'w') as datacsv:\n",
    "    writer = csv.writer(datacsv,dialect=(\"excel\"))\n",
    "    writer.writerow(['question_id','question','target_answer'])\n",
    "    for i in range(0,len(Question_id)):\n",
    "        writer.writerow([Question_id[i],Question[i],Target_answer[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('second_gan.csv', 'w') as datacsv:\n",
    "    writer = csv.writer(datacsv,dialect=(\"excel\"))\n",
    "    writer.writerow(['question_id','question','candidate_answer','target_answer'])\n",
    "    for i in range(0,len(Question_id)):\n",
    "        writer.writerow([Question_id[i],Question[i],Document[i],Target_answer[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import json\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab_word = Question + Document + Target_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence_word = []\n",
    "for s in vocab_word:\n",
    "    s_w = s.split(' ')\n",
    "    sentence_word.append(s_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64839"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Builds a vocabulary mapping from word to index based on the sentences.\n",
    "word_counts = Counter(itertools.chain(*sentence_word))\n",
    "# Mapping from index to word\n",
    "vocabulary_inv = [x[0] for x in word_counts.most_common()]\n",
    "# Mapping from word to index\n",
    "vocabulary = {x: i+4 for i, x in enumerate(vocabulary_inv)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabulary[\"_PAD\"] = 0\n",
    "vocabulary[\"_GO\"] = 1\n",
    "vocabulary[\"_EOS\"] = 2\n",
    "vocabulary[\"_UNK\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98349"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary['club']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "660"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary['large']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabulary_common = {key:value for key,value in vocabulary.items() if value < 30000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jsObj = json.dumps(vocabulary_common)  \n",
    "  \n",
    "fileObject = open('vocabulary_QA.json', 'w')  \n",
    "fileObject.write(jsObj)  \n",
    "fileObject.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
