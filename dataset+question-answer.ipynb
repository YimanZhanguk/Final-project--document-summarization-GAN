{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## question answer - GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## train GAN on this two dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import csv\\nwith open(\\'first_gan.csv\\', \\'w\\') as datacsv:\\n    writer = csv.writer(datacsv,dialect=(\"excel\"))\\n    writer.writerow([\\'question_id\\',\\'question\\',\\'target_answer\\'])\\n    for i in range(0,len(Question_id)):\\n        writer.writerow([Question_id[i],Question[i],Target_answer[i]])'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import csv\n",
    "with open('first_gan.csv', 'w') as datacsv:\n",
    "    writer = csv.writer(datacsv,dialect=(\"excel\"))\n",
    "    writer.writerow(['question_id','question','target_answer'])\n",
    "    for i in range(0,len(Question_id)):\n",
    "        writer.writerow([Question_id[i],Question[i],Target_answer[i]])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import csv\\nwith open(\\'second_gan.csv\\', \\'w\\') as datacsv:\\n    writer = csv.writer(datacsv,dialect=(\"excel\"))\\n    writer.writerow([\\'question_id\\',\\'question\\',\\'candidate_answer\\',\\'target_answer\\'])\\n    for i in range(0,len(Question_id)):\\n        writer.writerow([Question_id[i],Question[i],Document[i],Target_answer[i]])'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import csv\n",
    "with open('second_gan.csv', 'w') as datacsv:\n",
    "    writer = csv.writer(datacsv,dialect=(\"excel\"))\n",
    "    writer.writerow(['question_id','question','candidate_answer','target_answer'])\n",
    "    for i in range(0,len(Question_id)):\n",
    "        writer.writerow([Question_id[i],Question[i],Document[i],Target_answer[i]])'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import codecs\n",
    "from sklearn.utils import shuffle\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import re\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.ops import nn_ops\n",
    "from tensorflow.python.ops import tensor_array_ops\n",
    "from tensorflow.python.ops import embedding_ops\n",
    "from tensorflow.python.ops import variable_scope as vs\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import init_ops\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.util import nest\n",
    "from tensorflow.python.ops import variable_scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PAD_ID = 0\n",
    "GO_ID = 1\n",
    "EOS_ID = 2\n",
    "UNK_ID = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    prob = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sequence_loss_by_example(logits, targets, weights,\n",
    "                             average_across_timesteps=True,\n",
    "                             softmax_loss_function=None, name=None):\n",
    "    # print('sequence_loss_by_example')\n",
    "    if len(targets) != len(logits) or len(weights) != len(logits):\n",
    "        raise ValueError(\"Lengths of logits, weights, and targets must be the same \"\n",
    "                     \"%d, %d, %d.\" % (len(logits), len(weights), len(targets)))\n",
    "    with ops.name_scope(name, \"sequence_loss_by_example\",\n",
    "                      logits + targets + weights):\n",
    "        log_perp_list = []\n",
    "        for logit, target, weight in zip(logits, targets, weights):\n",
    "            if softmax_loss_function is None:\n",
    "                target = array_ops.reshape(target, [-1])\n",
    "                crossent = nn_ops.sparse_softmax_cross_entropy_with_logits(logit, target)\n",
    "            else:\n",
    "                crossent = softmax_loss_function(logit, target)\n",
    "            log_perp_list.append(crossent * weight)\n",
    "        log_perps = math_ops.add_n(log_perp_list)\n",
    "        if average_across_timesteps:\n",
    "            total_size = math_ops.add_n(weights)\n",
    "            total_size += 1e-12  # Just to avoid division by 0 for all-0 weights.\n",
    "            log_perps /= total_size\n",
    "    return log_perps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sequence_loss(logits, targets, weights,\n",
    "                  average_across_timesteps=True, average_across_batch=True,\n",
    "                  softmax_loss_function=None, name=None):\n",
    "    #print(\"sequence_loss\")\n",
    "    with ops.name_scope(name, \"sequence_loss\", logits + targets + weights):\n",
    "        cost = math_ops.reduce_sum(sequence_loss_by_example(\n",
    "                                                        logits, targets, weights,\n",
    "                                                        average_across_timesteps=average_across_timesteps,\n",
    "                                                        softmax_loss_function=softmax_loss_function))\n",
    "        if average_across_batch:\n",
    "            batch_size = array_ops.shape(targets[0])[0]\n",
    "            return cost / math_ops.cast(batch_size, cost.dtype)\n",
    "        else:\n",
    "            return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_BIAS_VARIABLE_NAME = \"bias\"\n",
    "_WEIGHTS_VARIABLE_NAME = \"kernel\"\n",
    "def linear(args,\n",
    "            output_size,\n",
    "            bias,\n",
    "            bias_initializer=None,\n",
    "            kernel_initializer=None):\n",
    "    if args is None or (nest.is_sequence(args) and not args):\n",
    "        raise ValueError(\"`args` must be specified\")\n",
    "    if not nest.is_sequence(args):\n",
    "        args = [args]\n",
    "\n",
    "    # Calculate the total size of arguments on dimension 1.\n",
    "    total_arg_size = 0\n",
    "    shapes = [a.get_shape() for a in args]\n",
    "    for shape in shapes:\n",
    "        if shape.ndims != 2:\n",
    "            raise ValueError(\"linear is expecting 2D arguments: %s\" % shapes)\n",
    "        if shape[1].value is None:\n",
    "            raise ValueError(\"linear expects shape[1] to be provided for shape %s, \"\n",
    "                       \"but saw %s\" % (shape, shape[1]))\n",
    "        else:\n",
    "            total_arg_size += shape[1].value\n",
    "\n",
    "    dtype = [a.dtype for a in args][0]\n",
    "    \n",
    "    # Now the computation.\n",
    "    scope = vs.get_variable_scope()\n",
    "    with vs.variable_scope(scope) as outer_scope:\n",
    "        weights = vs.get_variable(\n",
    "                                    _WEIGHTS_VARIABLE_NAME, [total_arg_size, output_size],\n",
    "                                    dtype=dtype,\n",
    "                                    initializer=kernel_initializer)\n",
    "        if len(args) == 1:\n",
    "            res = math_ops.matmul(args[0], weights)\n",
    "        else:\n",
    "            res = math_ops.matmul(array_ops.concat(args, 1), weights)\n",
    "        if not bias:\n",
    "            return res\n",
    "        with vs.variable_scope(outer_scope) as inner_scope:\n",
    "            inner_scope.set_partitioner(None)\n",
    "            if bias_initializer is None:\n",
    "                bias_initializer = init_ops.constant_initializer(0.0, dtype=dtype)\n",
    "            biases = vs.get_variable(\n",
    "                                      _BIAS_VARIABLE_NAME, [output_size],\n",
    "                                      dtype=dtype,\n",
    "                                        initializer=bias_initializer)\n",
    "        return nn_ops.bias_add(res, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def attention_decoder(decoder_inputs,\n",
    "                      initial_state,\n",
    "                      attention_states,\n",
    "                      cell,\n",
    "                      output_size=None,\n",
    "                      num_heads=1,\n",
    "                      loop_function=None,\n",
    "                      dtype=None,\n",
    "                      scope=None,\n",
    "                      initial_state_attention=False):\n",
    "\n",
    "    #print('attention_decoder')\n",
    "    if not decoder_inputs:\n",
    "        raise ValueError(\"Must provide at least 1 input to attention decoder.\")\n",
    "    if num_heads < 1:\n",
    "        raise ValueError(\"With less than 1 heads, use a non-attention decoder.\")\n",
    "    if attention_states.get_shape()[2].value is None:\n",
    "        raise ValueError(\"Shape[2] of attention_states must be known: %s\"\n",
    "                     % attention_states.get_shape())\n",
    "    if output_size is None:\n",
    "        output_size = cell.output_size\n",
    "\n",
    "    with variable_scope.variable_scope(scope or \"attention_decoder\", dtype=dtype) as scope:\n",
    "        dtype = scope.dtype\n",
    "\n",
    "        batch_size = array_ops.shape(decoder_inputs[0])[0]  # Needed for reshaping.\n",
    "        attn_length = attention_states.get_shape()[1].value\n",
    "        if attn_length is None:\n",
    "            attn_length = shape(attention_states)[1]\n",
    "        attn_size = attention_states.get_shape()[2].value\n",
    "\n",
    "        # To calculate W1 * h_t we use a 1-by-1 convolution, need to reshape before.\n",
    "        hidden = array_ops.reshape(attention_states, [-1, attn_length, 1, attn_size])\n",
    "        hidden_features = []\n",
    "        v = []\n",
    "        attention_vec_size = attn_size  # Size of query vectors for attention.\n",
    "        for a in xrange(num_heads):\n",
    "            k = variable_scope.get_variable(\"AttnW_%d\" % a,\n",
    "                                      [1, 1, attn_size, attention_vec_size])\n",
    "            hidden_features.append(nn_ops.conv2d(hidden, k, [1, 1, 1, 1], \"SAME\"))\n",
    "            v.append(variable_scope.get_variable(\"AttnV_%d\" % a, [attention_vec_size]))\n",
    "\n",
    "        state = initial_state\n",
    "\n",
    "        def attention(query):\n",
    "            \"\"\"Put attention masks on hidden using hidden_features and query.\"\"\"\n",
    "            #print(\"attention_decoder.attention\")\n",
    "            ds = []  # Results of attention reads will be stored here.\n",
    "            if nest.is_sequence(query):  # If the query is a tuple, flatten it.\n",
    "                query_list = nest.flatten(query)\n",
    "                for q in query_list:  # Check that ndims == 2 if specified.\n",
    "                    ndims = q.get_shape().ndims\n",
    "                    if ndims:\n",
    "                        assert ndims == 2\n",
    "                query = array_ops.concat(query_list,1)\n",
    "            for a in xrange(num_heads):\n",
    "                with variable_scope.variable_scope(\"Attention_%d\" % a):\n",
    "                    #print('调用linear')\n",
    "                    y = linear(query, attention_vec_size,True)\n",
    "                    y = array_ops.reshape(y, [-1, 1, 1, attention_vec_size])\n",
    "                    # Attention mask is a softmax of v^T * tanh(...).\n",
    "                    s = math_ops.reduce_sum(v[a] * math_ops.tanh(hidden_features[a] + y), [2, 3])\n",
    "                    a = nn_ops.softmax(s)\n",
    "                    # Now calculate the attention-weighted vector d.\n",
    "                    d = math_ops.reduce_sum(\n",
    "                    array_ops.reshape(a, [-1, attn_length, 1, 1]) * hidden,[1, 2])\n",
    "                    ds.append(array_ops.reshape(d, [-1, attn_size]))\n",
    "            return ds\n",
    "\n",
    "        outputs = []\n",
    "        prev = None\n",
    "        batch_attn_size = array_ops.stack([batch_size, attn_size])\n",
    "        attns = [array_ops.zeros(batch_attn_size, dtype=dtype)for _ in xrange(num_heads)]\n",
    "        for a in attns:  # Ensure the second shape of attention vectors is set.\n",
    "            a.set_shape([None, attn_size])\n",
    "        if initial_state_attention:\n",
    "            attns = attention(initial_state)\n",
    "        for i, inp in enumerate(decoder_inputs):\n",
    "            if i > 0:\n",
    "                variable_scope.get_variable_scope().reuse_variables()\n",
    "            # If loop_function is set, we use it instead of decoder_inputs.\n",
    "            if loop_function is not None and prev is not None:\n",
    "                with variable_scope.variable_scope(\"loop_function\", reuse=True):\n",
    "                    inp = loop_function(prev, i)\n",
    "            # Merge input and previous attentions into one vector of the right size.\n",
    "            input_size = inp.get_shape().with_rank(2)[1]\n",
    "            if input_size.value is None:\n",
    "                raise ValueError(\"Could not infer input size from input: %s\" % inp.name)\n",
    "                \n",
    "            #print('调用linear')\n",
    "            x = linear([inp] + attns, input_size,True)\n",
    "            cell_output, state = cell(x, state)\n",
    "            if i == 0 and initial_state_attention:\n",
    "                #print('找错1')\n",
    "                with variable_scope.variable_scope(variable_scope.get_variable_scope(),\n",
    "                                           reuse=True):\n",
    "                    #print(\"找错2\")\n",
    "                    attns = attention(state)\n",
    "            else:\n",
    "                #print(\"找错3\")\n",
    "                attns = attention(state)\n",
    "            \n",
    "            with variable_scope.variable_scope(\"AttnOutputProjection\"):\n",
    "                #print('output = linear([cell_output] + attns, output_size,True)')\n",
    "                output = linear([cell_output] + attns, output_size,True)\n",
    "            if loop_function is not None:\n",
    "                prev = output\n",
    "            #print('outputs.append(output)')\n",
    "            outputs.append(output)\n",
    "\n",
    "    return outputs, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _argmax_or_mcsearch(embedding, output_projection=None, update_embedding=True, mc_search=False):\n",
    "    def loop_function(prev, _):\n",
    "        if output_projection is not None:\n",
    "            prev = nn_ops.xw_plus_b(prev, output_projection[0], output_projection[1])\n",
    "\n",
    "\n",
    "        if isinstance(mc_search, bool):\n",
    "            prev_symbol = tf.reshape(tf.multinomial(prev, 1), [-1]) if mc_search else math_ops.argmax(prev, 1)\n",
    "        else:\n",
    "            prev_symbol = tf.cond(mc_search, lambda: tf.reshape(tf.multinomial(prev, 1), [-1]), lambda: tf.argmax(prev, 1))\n",
    "\n",
    "\n",
    "        emb_prev = embedding_ops.embedding_lookup(embedding, prev_symbol)\n",
    "        if not update_embedding:\n",
    "            emb_prev = array_ops.stop_gradient(emb_prev)\n",
    "        return emb_prev\n",
    "    return loop_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embedding_attention_decoder(decoder_inputs,\n",
    "                                initial_state,\n",
    "                                attention_states,\n",
    "                                cell,\n",
    "                                num_symbols,\n",
    "                                embedding_size,\n",
    "                                num_heads=1,\n",
    "                                output_size=None,\n",
    "                                output_projection=None,\n",
    "                                feed_previous=False,\n",
    "                                update_embedding_for_previous=True,\n",
    "                                dtype=None,\n",
    "                                scope=None,\n",
    "                                initial_state_attention=False,\n",
    "                                mc_search = False):\n",
    "    #print('embedding_attention_decoder')\n",
    "    if output_size is None:\n",
    "        output_size = cell.output_size\n",
    "    if output_projection is not None:\n",
    "        proj_biases = ops.convert_to_tensor(output_projection[1], dtype=dtype)\n",
    "        proj_biases.get_shape().assert_is_compatible_with([num_symbols])\n",
    "\n",
    "    with variable_scope.variable_scope(scope or \"embedding_attention_decoder\", dtype=dtype) as scope:\n",
    "        embedding = variable_scope.get_variable(\"embedding\",[num_symbols, embedding_size])\n",
    "\n",
    "        loop_function = None\n",
    "        if feed_previous == True:\n",
    "            loop_function = _argmax_or_mcsearch(embedding, output_projection, update_embedding_for_previous, mc_search)\n",
    "\n",
    "        emb_inp = [embedding_ops.embedding_lookup(embedding, i) for i in decoder_inputs]\n",
    "        return attention_decoder(\n",
    "                                emb_inp,\n",
    "                                initial_state,\n",
    "                                attention_states,\n",
    "                                cell,\n",
    "                                output_size=output_size,\n",
    "                                num_heads=num_heads,\n",
    "                                loop_function=loop_function,\n",
    "                                initial_state_attention=initial_state_attention,\n",
    "                                scope=scope)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# return output, state, encoder_state\n",
    "\n",
    "def embedding_attention_seq2seq(encoder_inputs,\n",
    "                                decoder_inputs,\n",
    "                                cell,\n",
    "                                num_encoder_symbols,\n",
    "                                num_decoder_symbols,\n",
    "                                embedding_size,\n",
    "                                num_heads=1,\n",
    "                                output_projection=None,\n",
    "                                feed_previous=False,\n",
    "                                dtype=None,\n",
    "                                scope=None,\n",
    "                                initial_state_attention=False,\n",
    "                                mc_search=False):\n",
    "\n",
    "    with variable_scope.variable_scope(scope or \"embedding_attention_seq2seq\", dtype=dtype) as scope:\n",
    "        dtype = scope.dtype\n",
    "        #print('embedding_attention_seq2seq')\n",
    "        \n",
    "        # Encoder.\n",
    "        #print('encoder_cell')\n",
    "        encoder_cell = tf.contrib.rnn.core_rnn_cell.EmbeddingWrapper(\n",
    "                cell, embedding_classes=num_encoder_symbols,\n",
    "                embedding_size=embedding_size)\n",
    "        #print('encoder_outputs, encoder_state = tf.contrib.rnn.static_rnn')\n",
    "        encoder_outputs, encoder_state = tf.contrib.rnn.static_rnn(\n",
    "                encoder_cell, encoder_inputs, dtype=dtype)\n",
    "        #print('encoder_outputs')\n",
    "        \n",
    "        # First calculate a concatenation of encoder outputs to put attention on.\n",
    "        #print('top-state')\n",
    "        #top_states = [array_ops.reshape([-1, 1, cell.output_size],e)for e in encoder_outputs]\n",
    "        top_states = tf.stack(encoder_outputs)\n",
    "        top_states = tf.transpose(top_states, [1,0,2])\n",
    "        #print('attention_state')\n",
    "        attention_states = array_ops.concat(top_states,1)\n",
    "\n",
    "        # Decoder.\n",
    "        #print('decoder')\n",
    "        output_size = None\n",
    "        if output_projection is None:\n",
    "            cell = rnn_cell.OutputProjectionWrapper(cell, num_decoder_symbols)\n",
    "            output_size = num_decoder_symbols\n",
    "\n",
    "        if isinstance(feed_previous, bool):\n",
    "            outputs, state = embedding_attention_decoder(\n",
    "                          decoder_inputs,\n",
    "                          encoder_state,\n",
    "                          attention_states,\n",
    "                          cell,\n",
    "                          num_decoder_symbols,\n",
    "                          embedding_size,\n",
    "                          num_heads=num_heads,\n",
    "                          output_size=output_size,\n",
    "                          output_projection=output_projection,\n",
    "                          feed_previous=feed_previous,\n",
    "                          initial_state_attention=initial_state_attention,\n",
    "                          mc_search=mc_search,\n",
    "                          scope=scope)\n",
    "            return outputs, state, encoder_state\n",
    "\n",
    "        # If feed_previous is a Tensor, we construct 2 graphs and use cond.\n",
    "        def decoder(feed_previous_bool):\n",
    "            reuse = None if feed_previous_bool else True\n",
    "            with variable_scope.variable_scope(variable_scope.get_variable_scope(), reuse=reuse) as scope:\n",
    "                outputs, state = embedding_attention_decoder(\n",
    "                            decoder_inputs,\n",
    "                            encoder_state,\n",
    "                            attention_states,\n",
    "                            cell,\n",
    "                            num_decoder_symbols,\n",
    "                            embedding_size,\n",
    "                            num_heads=num_heads,\n",
    "                            output_size=output_size,\n",
    "                            output_projection=output_projection,\n",
    "                            feed_previous=feed_previous_bool,\n",
    "                            update_embedding_for_previous=False,\n",
    "                            initial_state_attention=initial_state_attention,\n",
    "                            mc_search=mc_search,\n",
    "                            scope=scope)\n",
    "                state_list = [state]\n",
    "                if nest.is_sequence(state):\n",
    "                    state_list = nest.flatten(state)\n",
    "                return outputs + state_list\n",
    "\n",
    "        outputs_and_state = control_flow_ops.cond(feed_previous,\n",
    "                                              lambda: decoder(True),\n",
    "                                              lambda: decoder(False))\n",
    "        outputs_len = len(decoder_inputs)  # Outputs length same as decoder inputs.\n",
    "        state_list = outputs_and_state[outputs_len:]\n",
    "        state = state_list[0]\n",
    "        if nest.is_sequence(encoder_state):\n",
    "            state = nest.pack_sequence_as(structure=encoder_state,\n",
    "                                    flat_sequence=state_list)\n",
    "        return outputs_and_state[:outputs_len], state, encoder_state\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# return outputs, losses, encoder_states\n",
    "\n",
    "def model_with_buckets(encoder_inputs, decoder_inputs, targets, weights, buckets, vocab_size, batch_size, seq2seq,\n",
    "                       output_projection=None, softmax_loss_function=None, per_example_loss=False, name=None):\n",
    "    #print('model_with_buckets')\n",
    "    if len(encoder_inputs) < buckets[-1][0]:\n",
    "        raise ValueError(\"Length of encoder_inputs (%d) must be at least that of la\"\n",
    "                     \"st bucket (%d).\" % (len(encoder_inputs), buckets[-1][0]))\n",
    "    if len(targets) < buckets[-1][1]:\n",
    "        raise ValueError(\"Length of targets (%d) must be at least that of last\"\n",
    "                     \"bucket (%d).\" % (len(targets), buckets[-1][1]))\n",
    "    if len(weights) < buckets[-1][1]:\n",
    "        raise ValueError(\"Length of weights (%d) must be at least that of last\"\n",
    "                     \"bucket (%d).\" % (len(weights), buckets[-1][1]))\n",
    "\n",
    "    all_inputs = encoder_inputs + decoder_inputs + targets + weights\n",
    "    losses = []\n",
    "    outputs = []\n",
    "    encoder_states = []\n",
    "    with ops.name_scope(name, \"model_with_buckets\", all_inputs):\n",
    "        for j, bucket in enumerate(buckets):\n",
    "            with variable_scope.variable_scope(variable_scope.get_variable_scope(),\n",
    "                                         reuse=True if j > 0 else None):\n",
    "                bucket_outputs, decoder_states, encoder_state = seq2seq(encoder_inputs[:bucket[0]],\n",
    "                                    decoder_inputs[:bucket[1]])\n",
    "                outputs.append(bucket_outputs)\n",
    "                #print(\"bucket outputs: %s\" %bucket_outputs)\n",
    "                encoder_states.append(encoder_state)\n",
    "                if per_example_loss:\n",
    "                    losses.append(sequence_loss_by_example(\n",
    "                    outputs[-1], targets[:bucket[1]], weights[:bucket[1]],\n",
    "                    softmax_loss_function=softmax_loss_function))\n",
    "                else:\n",
    "                    # losses.append(sequence_loss_by_mle(outputs[-1], targets[:bucket[1]], vocab_size, bucket[1], batch_size, output_projection))\n",
    "                    losses.append(sequence_loss(outputs[-1], targets[:bucket[1]], weights[:bucket[1]], softmax_loss_function=softmax_loss_function))\n",
    "\n",
    "    return outputs, losses, encoder_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Seq2SeqModel(object):\n",
    "    def __init__(self, config,name_scope, forward_only,use_lstm=False,num_samples=512):\n",
    "\n",
    "        dtype=tf.float32\n",
    "        \n",
    "        source_vocab_size = config.vocab_size\n",
    "        target_vocab_size = config.vocab_size\n",
    "        size= config.emb_dim\n",
    "\n",
    "        self.buckets = config.buckets\n",
    "        self.batch_size = config.batch_size\n",
    "        self.learning_rate = tf.Variable(float(config.learning_rate), trainable=False)\n",
    "        self.learning_rate_decay_op = self.learning_rate.assign(\n",
    "            self.learning_rate * config.learning_rate_decay_factor)\n",
    "        self.global_step = tf.Variable(0, trainable=False)\n",
    "        max_gradient_norm = config.max_gradient_norm\n",
    "        self.forward_only = tf.placeholder(tf.bool, name=\"forward_only\")\n",
    "        #self.num_layers = config.num_layers\n",
    "        num_layers = config.num_layers\n",
    "        self.max_gradient_norm = config.max_gradient_norm\n",
    "        \n",
    "        # If we use sampled softmax, we need an output projection.\n",
    "        output_projection = None\n",
    "        softmax_loss_function = None\n",
    "        \n",
    "        # ADD\n",
    "        self.mc_search = tf.placeholder(tf.bool, name=\"mc_search\")\n",
    "        self.up_reward = tf.placeholder(tf.bool, name=\"up_reward\")\n",
    "        self.reward_bias = tf.get_variable(\"reward_bias\", [1], dtype=tf.float32)\n",
    "        \n",
    "        # Sampled softmax only makes sense if we sample less than vocabulary size.\n",
    "        if num_samples > 0 and num_samples < target_vocab_size:\n",
    "            w = tf.get_variable(\"proj_w\", [size, target_vocab_size])\n",
    "            w_t = tf.transpose(w)\n",
    "            b = tf.get_variable(\"proj_b\", [target_vocab_size])\n",
    "            output_projection = (w, b)\n",
    "\n",
    "            def sampled_loss(inputs, labels):\n",
    "                \n",
    "                labels = tf.reshape(labels, [-1, 1])\n",
    "                local_w_t = tf.cast(w_t, tf.float32)\n",
    "                local_b = tf.cast(b, tf.float32)\n",
    "                local_inputs = tf.cast(inputs, tf.float32)\n",
    "                \n",
    "                return tf.cast(\n",
    "                    tf.nn.sampled_softmax_loss(local_w_t, local_b, labels, local_inputs,\n",
    "                                               num_samples, target_vocab_size), dtype)\n",
    "            softmax_loss_function = sampled_loss\n",
    "\n",
    "        # Create the internal multi-layer cell for our RNN.\n",
    "        single_cell = tf.contrib.rnn.GRUCell(size)\n",
    "        print('single_cell')\n",
    "        if use_lstm:\n",
    "            single_cell = tf.contrib.rnn.LSTMCell(size)\n",
    "        cell = single_cell\n",
    "        cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=0.5)\n",
    "        if num_layers > 1:\n",
    "            cell = tf.contrib.rnn.MultiRNNCell([single_cell] * num_layers)\n",
    "        # tf.contrib.seq2seq\n",
    "        # The seq2seq function: we use embedding for the input and attention.\n",
    "        def seq2seq_f(encoder_inputs, decoder_inputs, do_decode):\n",
    "            return embedding_attention_seq2seq(\n",
    "                  encoder_inputs, decoder_inputs, cell,\n",
    "                  num_encoder_symbols=source_vocab_size,\n",
    "                  num_decoder_symbols=target_vocab_size,\n",
    "                  embedding_size=size,\n",
    "                  output_projection=output_projection,\n",
    "                  feed_previous=do_decode)\n",
    "\n",
    "        # Feeds for inputs.\n",
    "        self.encoder_inputs = []\n",
    "        self.decoder_inputs = []\n",
    "        self.target_weights = []\n",
    "        for i in xrange(self.buckets[-1][0]):  # Last bucket is the biggest one.\n",
    "            self.encoder_inputs.append(tf.placeholder(tf.int32, shape=[None],\n",
    "                                                name=\"encoder{0}\".format(i)))\n",
    "        for i in xrange(self.buckets[-1][1] + 1):\n",
    "            self.decoder_inputs.append(tf.placeholder(tf.int32, shape=[None],\n",
    "                                                name=\"decoder{0}\".format(i)))\n",
    "            self.target_weights.append(tf.placeholder(tf.float32, shape=[None],\n",
    "                                                name=\"weight{0}\".format(i)))\n",
    "        self.reward = [tf.placeholder(tf.float32, name=\"reward_%i\" % i) for i in range(len(self.buckets))] # ADD\n",
    "        \n",
    "        \n",
    "        # Our targets are decoder inputs shifted by one.\n",
    "        targets = [self.decoder_inputs[i + 1] for i in xrange(len(self.decoder_inputs) - 1)]\n",
    "\n",
    "        self.outputs, self.losses,self.encoder_state  = model_with_buckets(\n",
    "                  self.encoder_inputs, self.decoder_inputs, targets,\n",
    "                  self.target_weights, self.buckets, source_vocab_size, self.batch_size,\n",
    "                  lambda x, y: seq2seq_f(x, y, tf.where(self.forward_only, True, False)),\n",
    "                  output_projection=output_projection,\n",
    "                  softmax_loss_function=softmax_loss_function)\n",
    "        \n",
    "        for b in xrange(len(self.buckets)):\n",
    "            self.outputs[b] = [\n",
    "                tf.cond(\n",
    "                    self.forward_only,\n",
    "                    lambda: tf.matmul(output, output_projection[0]) + output_projection[1],\n",
    "                    lambda: output\n",
    "                )\n",
    "                for output in self.outputs[b]\n",
    "            ]\n",
    "        \n",
    "        if not forward_only:\n",
    "            with tf.name_scope(\"gradient_descent\"):\n",
    "                self.gradient_norms = []\n",
    "                self.updates = []\n",
    "                self.aj_losses = []\n",
    "                self.gen_params = [p for p in tf.trainable_variables() if name_scope in p.name]\n",
    "                opt = tf.train.AdamOptimizer()\n",
    "                for b in xrange(len(self.buckets)):\n",
    "                    R =  tf.subtract(self.reward[b], self.reward_bias)\n",
    "                    adjusted_loss = tf.cond(self.up_reward,\n",
    "                                              lambda:tf.multiply(self.losses[b], self.reward[b]),\n",
    "                                              lambda: self.losses[b])\n",
    "\n",
    "                    self.aj_losses.append(adjusted_loss)\n",
    "                    gradients = tf.gradients(adjusted_loss, self.gen_params)\n",
    "                    clipped_gradients, norm = tf.clip_by_global_norm(gradients, self.max_gradient_norm)\n",
    "                    self.gradient_norms.append(norm)\n",
    "                    self.updates.append(opt.apply_gradients(\n",
    "                        zip(clipped_gradients, self.gen_params), global_step=self.global_step))\n",
    "\n",
    "        self.gen_variables = [k for k in tf.global_variables() if name_scope in k.name]\n",
    "        self.saver = tf.train.Saver(tf.global_variables())\n",
    "\n",
    "    def step(self, session, encoder_inputs, decoder_inputs, target_weights,\n",
    "           bucket_id, forward_only=True, reward=1, mc_search=False, up_reward=False, debug=True):\n",
    "        #print(\"model.step\")\n",
    "        # Check if the sizes match.\n",
    "        encoder_size, decoder_size = self.buckets[bucket_id]\n",
    "        if len(encoder_inputs) != encoder_size:\n",
    "            raise ValueError(\"Encoder length must be equal to the one in bucket,\"\n",
    "                       \" %d != %d.\" % (len(encoder_inputs), encoder_size))\n",
    "        if len(decoder_inputs) != decoder_size:\n",
    "            raise ValueError(\"Decoder length must be equal to the one in bucket,\"\n",
    "                       \" %d != %d.\" % (len(decoder_inputs), decoder_size))\n",
    "        if len(target_weights) != decoder_size:\n",
    "            raise ValueError(\"Weights length must be equal to the one in bucket,\"\n",
    "                       \" %d != %d.\" % (len(target_weights), decoder_size))\n",
    "        #print(\"input feed\")\n",
    "        # Input feed: encoder inputs, decoder inputs, target_weights, as provided.\n",
    "        input_feed = {self.forward_only.name: forward_only,\n",
    "                      self.up_reward.name:  up_reward,\n",
    "                      self.mc_search.name: mc_search\n",
    "                     }\n",
    "        for l in xrange(len(self.buckets)):\n",
    "            input_feed[self.reward[l].name] = reward\n",
    "        for l in xrange(encoder_size):\n",
    "            input_feed[self.encoder_inputs[l].name] = encoder_inputs[l]\n",
    "        for l in xrange(decoder_size):\n",
    "            input_feed[self.decoder_inputs[l].name] = decoder_inputs[l]\n",
    "            input_feed[self.target_weights[l].name] = target_weights[l]\n",
    "        #print(\"last_target\")\n",
    "        # Since our targets are decoder inputs shifted by one, we need one more.\n",
    "        last_target = self.decoder_inputs[decoder_size].name\n",
    "        input_feed[last_target] = np.zeros([self.batch_size], dtype=np.int32)\n",
    "\n",
    "        # Output feed: depends on whether we do a backward step or not.\n",
    "        if not forward_only:\n",
    "            #print(\"not forward_only\")\n",
    "            output_feed = [self.updates[bucket_id],  # Update Op that does SGD.\n",
    "                     self.gradient_norms[bucket_id],  # Gradient norm.\n",
    "                     self.losses[bucket_id]]  # Loss for this batch.\n",
    "        else:\n",
    "            #print(\"forward_only\")\n",
    "            output_feed = [self.losses[bucket_id]]  # Loss for this batch.\n",
    "            for l in xrange(decoder_size):  # Output logits.\n",
    "                output_feed.append(self.outputs[bucket_id][l])\n",
    "\n",
    "        outputs = session.run(output_feed, input_feed)\n",
    "        if not forward_only:\n",
    "              return outputs[1], outputs[2], None  # Gradient norm, loss, no outputs.\n",
    "        else:\n",
    "              return None, outputs[0], outputs[1:]  # No gradient norm, loss, outputs.\n",
    "\n",
    "    def get_batch(self, data, bucket_id):\n",
    "\n",
    "        encoder_size, decoder_size = self.buckets[bucket_id]\n",
    "        encoder_inputs, decoder_inputs = [], []\n",
    "\n",
    "        for _ in xrange(self.batch_size):\n",
    "            encoder_input, decoder_input = random.choice(data[bucket_id])\n",
    "\n",
    "            # Encoder inputs are padded and then reversed.\n",
    "            encoder_pad = [PAD_ID] * (encoder_size - len(encoder_input))\n",
    "            encoder_inputs.append(list(reversed(encoder_input + encoder_pad)))\n",
    "\n",
    "            # Decoder inputs get an extra \"GO\" symbol, and are padded then.\n",
    "            decoder_pad_size = decoder_size - len(decoder_input) - 1\n",
    "            decoder_inputs.append([GO_ID] + decoder_input +\n",
    "                            [PAD_ID] * decoder_pad_size)\n",
    "\n",
    "        # Now we create batch-major vectors from the data selected above.\n",
    "        batch_encoder_inputs, batch_decoder_inputs, batch_weights = [], [], []\n",
    "\n",
    "        # Batch encoder inputs are just re-indexed encoder_inputs.\n",
    "        for length_idx in xrange(encoder_size):\n",
    "            batch_encoder_inputs.append(\n",
    "                np.array([encoder_inputs[batch_idx][length_idx]\n",
    "                    for batch_idx in xrange(self.batch_size)], dtype=np.int32))\n",
    "\n",
    "        # Batch decoder inputs are re-indexed decoder_inputs, we create weights.\n",
    "        for length_idx in xrange(decoder_size):\n",
    "            batch_decoder_inputs.append(\n",
    "                np.array([decoder_inputs[batch_idx][length_idx]\n",
    "                    for batch_idx in xrange(self.batch_size)], dtype=np.int32))\n",
    "\n",
    "            # Create target_weights to be 0 for targets that are padding.\n",
    "            batch_weight = np.ones(self.batch_size, dtype=np.float32)\n",
    "            for batch_idx in xrange(self.batch_size):\n",
    "                # We set weight to 0 if the corresponding target is a PAD symbol.\n",
    "                # The corresponding target is decoder_input shifted by 1 forward.\n",
    "                if length_idx < decoder_size - 1:\n",
    "                    target = decoder_inputs[batch_idx][length_idx + 1]\n",
    "                if length_idx == decoder_size - 1 or target == PAD_ID:\n",
    "                    batch_weight[batch_idx] = 0.0\n",
    "            batch_weights.append(batch_weight)\n",
    "        return batch_encoder_inputs, batch_decoder_inputs, batch_weights, encoder_inputs,decoder_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'with open(\\'first_gan.csv\\', \\'w\\') as datacsv:\\n    writer = csv.writer(datacsv,dialect=(\"excel\"))\\n    writer.writerow([\\'question_id\\',\\'question\\',\\'target_answer\\'])'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''with open('first_gan.csv', 'w') as datacsv:\n",
    "    writer = csv.writer(datacsv,dialect=(\"excel\"))\n",
    "    writer.writerow(['question_id','question','target_answer'])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(config):\n",
    "\n",
    "    train_data_set = [[] for _ in config.buckets]\n",
    "    dev_data_set = [[] for _ in config.buckets]\n",
    "\n",
    "    s2s_data = pd.read_csv('second_gan.csv')\n",
    "    train_data = s2s_data[0:25000]\n",
    "    dev_data = s2s_data[25000:]\n",
    "    \n",
    "    train_source = train_data['candidate_answer']\n",
    "    train_target = train_data['target_answer']\n",
    "    \n",
    "    dev_source = dev_data['candidate_answer']\n",
    "    dev_target = dev_data['target_answer']\n",
    "    \n",
    "    vocabulary = json.load(open('vocabulary_QA.json','r'))\n",
    "    \n",
    "    for m in range(0,len(train_source)):\n",
    "        if m % 10000 == 0:\n",
    "            print(\"  reading train data line %d\" % m)\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "        source_sen = train_source[m]\n",
    "        target_sen = train_target[m]\n",
    "            \n",
    "        source_word = []\n",
    "        target_word = []\n",
    "        \n",
    "        try:\n",
    "            s_w = source_sen.split(' ')\n",
    "        except:\n",
    "            s_w = ['float']\n",
    "        for i in range(0,len(s_w)):\n",
    "            s_w[i] = s_w[i].replace('.','')\n",
    "            s_w[i] = s_w[i].replace(',','')\n",
    "            s_w[i] = s_w[i].replace('?','')\n",
    "            s_w[i] = s_w[i].replace('(','')\n",
    "            s_w[i] = s_w[i].replace(')','')\n",
    "            s_w[i] = s_w[i].replace('!','')\n",
    "            s_w[i] = s_w[i].lower()\n",
    "            source_word.append(s_w[i])\n",
    "            \n",
    "        s_w = target_sen.split(' ')\n",
    "        for i in range(0,len(s_w)):\n",
    "            s_w[i] = s_w[i].replace('.','')\n",
    "            s_w[i] = s_w[i].replace(',','')\n",
    "            s_w[i] = s_w[i].replace('?','')\n",
    "            s_w[i] = s_w[i].replace('(','')\n",
    "            s_w[i] = s_w[i].replace(')','')\n",
    "            s_w[i] = s_w[i].replace('!','')\n",
    "            s_w[i] = s_w[i].lower()\n",
    "            target_word.append(s_w[i])            \n",
    "            \n",
    "        source_ids = []\n",
    "        target_ids = []\n",
    "            \n",
    "        # convert to number\n",
    "        \n",
    "        for w in source_word:\n",
    "            try:\n",
    "                source_ids.append(vocabulary[w])\n",
    "            except:\n",
    "                source_ids.append(3)# 3 is UNK token\n",
    "                \n",
    "        # add start tag to target sentence\n",
    "        #target_ids.append(1) # 1 is _GO: start token\n",
    "  \n",
    "        for w in target_word:\n",
    "            try:\n",
    "                target_ids.append(vocabulary[w])\n",
    "            except:\n",
    "                target_ids.append(3)# 3 is UNK token\n",
    "\n",
    "        # add finish tag to target sentence. \n",
    "        target_ids.append(EOS_ID) # EOS_ID is end token\n",
    "        \n",
    "        \n",
    "        # bucket data\n",
    "        #config.buckets:  [bucket_id, (source_size, target_size)]\n",
    "        for bucket_id, (source_size, target_size) in enumerate(config.buckets): #[bucket_id, (source_size, target_size)]\n",
    "            if len(source_ids) < source_size and len(target_ids) < target_size:\n",
    "                train_data_set[bucket_id].append([source_ids, target_ids])\n",
    "                break\n",
    "                 \n",
    "    for m in range(25000,25000+len(dev_source)):\n",
    "        if m % 10000 == 0:\n",
    "            print(\"  reading dev data line %d\" % m)\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "        source_sen = dev_source[m]\n",
    "        target_sen = dev_target[m]\n",
    " \n",
    "        source_word = []\n",
    "        target_word = []\n",
    "        \n",
    "        try:\n",
    "            s_w = source_sen.split(' ')\n",
    "        except:\n",
    "            s_w = ['float']\n",
    "        for i in range(0,len(s_w)):\n",
    "            s_w[i] = s_w[i].replace('.','')\n",
    "            s_w[i] = s_w[i].replace(',','')\n",
    "            s_w[i] = s_w[i].replace('?','')\n",
    "            s_w[i] = s_w[i].replace('(','')\n",
    "            s_w[i] = s_w[i].replace(')','')\n",
    "            s_w[i] = s_w[i].replace('!','')\n",
    "            s_w[i] = s_w[i].lower()\n",
    "            source_word.append(s_w[i])\n",
    "            \n",
    "        s_w = target_sen.split(' ')\n",
    "        for i in range(0,len(s_w)):\n",
    "            s_w[i] = s_w[i].replace('.','')\n",
    "            s_w[i] = s_w[i].replace(',','')\n",
    "            s_w[i] = s_w[i].replace('?','')\n",
    "            s_w[i] = s_w[i].replace('(','')\n",
    "            s_w[i] = s_w[i].replace(')','')\n",
    "            s_w[i] = s_w[i].replace('!','')\n",
    "            s_w[i] = s_w[i].lower()\n",
    "            target_word.append(s_w[i])    \n",
    "            \n",
    "        source_ids = []\n",
    "        target_ids = []\n",
    "            \n",
    "        # convert to number\n",
    "        for w in source_word:\n",
    "            try:\n",
    "                source_ids.append(vocabulary[w])\n",
    "            except:\n",
    "                source_ids.append(3)\n",
    "                \n",
    "        #target_ids.append(1) # 1 is _GO: start token\n",
    "        for w in target_word:\n",
    "            try:\n",
    "                target_ids.append(vocabulary[w])\n",
    "            except:\n",
    "                target_ids.append(3)\n",
    "\n",
    "        # add finish tag to target sentence. \n",
    "        target_ids.append(EOS_ID) # End token\n",
    "                \n",
    "        # bucket data\n",
    "        #config.buckets:  [bucket_id, (source_size, target_size)]\n",
    "        for bucket_id, (source_size, target_size) in enumerate(config.buckets): #[bucket_id, (source_size, target_size)]\n",
    "            if len(source_ids) < source_size and len(target_ids) < target_size:\n",
    "                dev_data_set[bucket_id].append([source_ids, target_ids])\n",
    "                break\n",
    "                                \n",
    "    return vocabulary,train_data_set,dev_data_set\n",
    "    #,train_query,dev_query\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_data(gen_config):\n",
    "    vocab, train_set,dev_set = read_data(gen_config)\n",
    "    rev_vocab = {v: k for k, v in vocab.items()}\n",
    "    return vocab, rev_vocab, dev_set, train_set\n",
    "    #,train_query,dev_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(session, gen_config, forward_only,name_scope, initializer=None):\n",
    "    \"\"\"Create translation model and initialize or load parameters in session.\"\"\"\n",
    "    with tf.variable_scope(name_or_scope=name_scope, initializer=initializer):\n",
    "        model = Seq2SeqModel(gen_config, name_scope=name_scope, forward_only=forward_only)\n",
    "        \n",
    "        # checkpoint\n",
    "        gen_ckpt_dir = os.path.abspath(os.path.join(gen_config.train_dir, \"checkpoints\"))\n",
    "        # os.path.abspath: 返回path规范化的绝对路径。 \n",
    "        ckpt = tf.train.get_checkpoint_state(gen_ckpt_dir)\n",
    "        \n",
    "        if ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n",
    "            print(\"Reading Gen model parameters from %s\" % ckpt.model_checkpoint_path)\n",
    "            model.saver.restore(session, ckpt.model_checkpoint_path)\n",
    "            #return model\n",
    "        else:\n",
    "            print(\"Created Gen model with fresh parameters.\")\n",
    "            gen_global_variables = [gv for gv in tf.global_variables() if name_scope in gv.name]\n",
    "            session.run(tf.variables_initializer(gen_global_variables))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pre train generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(gen_config):\n",
    "    \n",
    "    vocab, rev_vocab, dev_set, train_set = prepare_data(gen_config)\n",
    "    \n",
    "    for b_set in train_set:\n",
    "        print(\"bucket_set: \", len(b_set))\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "    #with tf.device(\"/gpu:1\"):\n",
    "        # Create model.\n",
    "        print(\"Creating %d layers of %d units.\" % (gen_config.num_layers, gen_config.emb_dim))\n",
    "        model = create_model(sess, gen_config, forward_only=False,name_scope=gen_config.name_model)\n",
    "        \n",
    "        #size of each bucket in the train_dataset.\n",
    "        train_bucket_sizes = [len(train_set[b]) for b in xrange(len(gen_config.buckets))]\n",
    "        # add them to get total train dataset size\n",
    "        train_total_size = float(sum(train_bucket_sizes))\n",
    "        # 0~1 --> id of bucket data.\n",
    "        train_buckets_scale = [sum(train_bucket_sizes[:i + 1]) / train_total_size\n",
    "                               for i in xrange(len(train_bucket_sizes))]\n",
    "\n",
    "        # This is the training loop.\n",
    "        step_time, loss = 0.0, 0.0\n",
    "        current_step = 0\n",
    "        previous_losses = []\n",
    "        gen_loss_summary = tf.Summary()\n",
    "        gen_writer = tf.summary.FileWriter(gen_config.tensorboard_dir, sess.graph)\n",
    "        print(\"training.......\")\n",
    "        while True:\n",
    "            # Choose a bucket.\n",
    "            # Choose a bucket according to data distribution. We pick a random number\n",
    "            # in [0, 1] and use the corresponding interval in train_buckets_scale.\n",
    "            random_number_01 = np.random.random_sample()\n",
    "            bucket_id = min([i for i in xrange(len(train_buckets_scale)) if train_buckets_scale[i] > random_number_01])\n",
    "\n",
    "            \n",
    "            # Get a batch and make a step.\n",
    "            start_time = time.time()\n",
    "            encoder_inputs, decoder_inputs, target_weights,_,_ = model.get_batch(train_set, bucket_id)\n",
    "            # model.get_batch 和 model.step 都是seq2seq里的函数。\n",
    "            _, step_loss, _ = model.step(sess, encoder_inputs, decoder_inputs, target_weights, bucket_id, forward_only=False)\n",
    "\n",
    "            step_time += (time.time() - start_time) / gen_config.steps_per_checkpoint\n",
    "            loss += step_loss / gen_config.steps_per_checkpoint\n",
    "            current_step += 1\n",
    "\n",
    "            \n",
    "            \n",
    "            if current_step % gen_config.steps_per_checkpoint == 0:\n",
    "                bucket_value = gen_loss_summary.value.add()\n",
    "                bucket_value.tag = gen_config.name_loss\n",
    "                bucket_value.simple_value = float(loss)\n",
    "                gen_writer.add_summary(gen_loss_summary, int(model.global_step.eval()))\n",
    "\n",
    "                # Print statistics for the previous epoch.\n",
    "                perplexity = math.exp(loss) if loss < 300 else float('inf')\n",
    "                print (\"global step %d learning rate %.4f step-time %.2f perplexity \"\n",
    "                       \"%.2f\" % (model.global_step.eval(), model.learning_rate.eval(),\n",
    "                                 step_time, perplexity))\n",
    "\n",
    "                # Decrease learning rate if no improvement was seen over last 3 times.\n",
    "                if len(previous_losses) > 2 and loss > max(previous_losses[-3:]):\n",
    "                    sess.run(model.learning_rate_decay_op)\n",
    "                previous_losses.append(loss)\n",
    "                \n",
    "                if current_step % (gen_config.steps_per_checkpoint * 3) == 0:\n",
    "                    print(\"current_step: %d, save model\" %(current_step))\n",
    "                    gen_ckpt_dir = os.path.abspath(os.path.join(gen_config.train_dir, \"checkpoints\"))\n",
    "                    if not os.path.exists(gen_ckpt_dir):\n",
    "                        #os.makedirs() 方法用于递归创建目录\n",
    "                        os.makedirs(gen_ckpt_dir)\n",
    "                    checkpoint_path = os.path.join(gen_ckpt_dir, \"chitchat.model\")\n",
    "                    model.saver.save(sess, checkpoint_path, global_step=model.global_step)\n",
    "\n",
    "                step_time, loss = 0.0, 0.0\n",
    "                sys.stdout.flush()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class gen_config(object):\n",
    "    beam_size = 10\n",
    "    learning_rate = 0.5\n",
    "    learning_rate_decay_factor = 0.99\n",
    "    max_gradient_norm = 2.0\n",
    "    batch_size = 64\n",
    "    emb_dim = 256\n",
    "    num_layers = 4\n",
    "    vocab_size = 250000\n",
    "    name_model = \"st_model\"\n",
    "    train_dir = \"./gen_data_d/\"\n",
    "    tensorboard_dir = \"./d_tensorboard/gen_log/\"\n",
    "    name_loss = \"gen_loss\"\n",
    "    teacher_loss = \"teacher_loss\"\n",
    "    reward_name = \"reward\"\n",
    "    max_train_data_size = 0\n",
    "    steps_per_checkpoint = 100\n",
    "    buckets = [(5,15),(10,20),(15,25),(30,30)]\n",
    "    buckets_concat = [(5,15),(10,20),(15,25),(30,30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  reading train data line 0\n",
      "  reading train data line 10000\n",
      "  reading train data line 20000\n",
      "bucket_set:  0\n",
      "bucket_set:  673\n",
      "bucket_set:  5521\n",
      "bucket_set:  8373\n",
      "Creating 4 layers of 256 units.\n",
      "single_cell\n",
      "Reading Gen model parameters from /Users/zhangyiman/final project/gen_data_d/checkpoints/chitchat.model-3600\n",
      "training.......\n",
      "global step 3700 learning rate 0.5000 step-time 3.95 perplexity 28.32\n",
      "global step 3800 learning rate 0.5000 step-time 3.96 perplexity 23.63\n",
      "global step 3900 learning rate 0.5000 step-time 3.98 perplexity 21.50\n",
      "current_step: 300, save model\n",
      "global step 4000 learning rate 0.5000 step-time 3.94 perplexity 19.89\n",
      "global step 4100 learning rate 0.5000 step-time 4.02 perplexity 18.65\n",
      "global step 4200 learning rate 0.5000 step-time 4.06 perplexity 17.02\n",
      "current_step: 600, save model\n",
      "global step 4300 learning rate 0.5000 step-time 3.61 perplexity 15.80\n",
      "global step 4400 learning rate 0.5000 step-time 3.71 perplexity 14.42\n",
      "global step 4500 learning rate 0.5000 step-time 3.98 perplexity 13.53\n",
      "current_step: 900, save model\n",
      "global step 4600 learning rate 0.5000 step-time 3.98 perplexity 12.75\n",
      "global step 4700 learning rate 0.5000 step-time 4.17 perplexity 11.43\n",
      "global step 4800 learning rate 0.5000 step-time 3.99 perplexity 10.83\n",
      "current_step: 1200, save model\n",
      "global step 4900 learning rate 0.5000 step-time 3.93 perplexity 10.28\n",
      "global step 5000 learning rate 0.5000 step-time 3.93 perplexity 9.42\n",
      "global step 5100 learning rate 0.5000 step-time 4.04 perplexity 9.03\n",
      "current_step: 1500, save model\n",
      "global step 5200 learning rate 0.5000 step-time 3.79 perplexity 8.07\n",
      "global step 5300 learning rate 0.5000 step-time 3.58 perplexity 7.95\n",
      "global step 5400 learning rate 0.5000 step-time 3.57 perplexity 7.48\n",
      "current_step: 1800, save model\n",
      "global step 5500 learning rate 0.5000 step-time 3.55 perplexity 6.86\n",
      "global step 5600 learning rate 0.5000 step-time 3.52 perplexity 6.50\n",
      "global step 5700 learning rate 0.5000 step-time 3.59 perplexity 6.22\n",
      "current_step: 2100, save model\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-a680810ee827>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-9679ac581f77>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(gen_config)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mencoder_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbucket_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;31m# model.get_batch 和 model.step 都是seq2seq里的函数。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbucket_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mstep_time\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mgen_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_per_checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-2e48a7cdc271>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, session, encoder_inputs, decoder_inputs, target_weights, bucket_id, forward_only, reward, mc_search, up_reward, debug)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0moutput_feed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbucket_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_feed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_feed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mforward_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m               \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# Gradient norm, loss, no outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(gen_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## seq2seq decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class gen_config(object):\n",
    "    beam_size = 10\n",
    "    learning_rate = 0.5\n",
    "    learning_rate_decay_factor = 0.99\n",
    "    max_gradient_norm = 2.0\n",
    "    batch_size = 1\n",
    "    emb_dim = 256\n",
    "    num_layers = 4\n",
    "    vocab_size = 250000\n",
    "    name_model = \"st_model\"\n",
    "    train_dir = \"./gen_data_d/\"\n",
    "    tensorboard_dir = \"./d_tensorboard/gen_log/\"\n",
    "    name_loss = \"gen_loss\"\n",
    "    teacher_loss = \"teacher_loss\"\n",
    "    reward_name = \"reward\"\n",
    "    max_train_data_size = 0\n",
    "    steps_per_checkpoint = 100\n",
    "    buckets = [(5,15),(10,20),(15,25),(30,30)]\n",
    "    buckets_concat = [(5,15),(10,20),(15,25),(30,30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode(decode_num_step):\n",
    "    \n",
    "    # Load vocabularies.\n",
    "    vocab, rev_vocab, dev_set, train_set = prepare_data(gen_config)\n",
    "        \n",
    "        \n",
    "    train_bucket_sizes = [len(train_set[b]) for b in xrange(len(gen_config.buckets))]\n",
    "    train_total_size = float(sum(train_bucket_sizes))\n",
    "    train_buckets_scale = [sum(train_bucket_sizes[:i + 1]) / train_total_size\n",
    "                           for i in xrange(len(train_bucket_sizes))]\n",
    "    \n",
    "    input_document = []\n",
    "    target_summary = []\n",
    "    generated_summary = []\n",
    "    with tf.Session() as sess:\n",
    "        # Create model and load parameters.\n",
    "        model = create_model(sess, gen_config, forward_only=True, name_scope=gen_config.name_model)\n",
    "\n",
    "        num_step = 0\n",
    "        while num_step < decode_num_step:\n",
    "            print(\"generating num_step: \", num_step)\n",
    "            random_number_01 = np.random.random_sample()\n",
    "            bucket_id = min([i for i in xrange(len(train_buckets_scale))\n",
    "                             if train_buckets_scale[i] > random_number_01])\n",
    "            # Get a 1-element batch to feed the sentence to the model.\n",
    "            encoder_inputs, decoder_inputs, target_weights, _encoder_inputs, _decoder_inputs = model.get_batch(\n",
    "                  train_set, bucket_id)#get_batch(train_set,bucket_id)\n",
    "            # Get output logits for the sentence.\n",
    "            _, _, output_logits = model.step(sess, encoder_inputs, decoder_inputs,target_weights, bucket_id, True)\n",
    "            # This is a greedy decoder - outputs are just argmaxes of output_logits.\n",
    "            outputs = [int(np.argmax(logit, axis=1)) for logit in output_logits]\n",
    "            #print('batch_encoder_input')\n",
    "            #print(\" \".join([str(rev_vocab[an]) for an in encoder_inputs]))\n",
    "            # If there is an EOS symbol in outputs, cut them at that point.\n",
    "            if EOS_ID in outputs:\n",
    "                outputs = outputs[:outputs.index(EOS_ID)]\n",
    "            # Print out French sentence corresponding to outputs.\n",
    "            summary_g = \" \".join([tf.compat.as_str(rev_vocab[output]) for output in outputs])\n",
    "            print(summary_g)\n",
    "            generated_summary.append(summary_g)\n",
    "            \n",
    "            for query, answer,outputs in zip(_encoder_inputs, _decoder_inputs,outputs):\n",
    "\n",
    "                answer_str = \" \".join([str(rev_vocab[an]) for an in answer])\n",
    "                answer_str = answer_str.replace('_GO ','')\n",
    "                answer_str = answer_str.replace(' _EOS','')\n",
    "                answer_str = answer_str.replace(' _PAD','')\n",
    "                print(answer_str)\n",
    "                target_summary.append(answer_str)\n",
    "                \n",
    "                query_str = \" \".join([str(rev_vocab[qu]) for qu in query])\n",
    "                query_str = query_str.replace(' _PAD','')\n",
    "                #print(query_str)\n",
    "                document_str = query_str.split(' ')\n",
    "                i = len(document_str)-1\n",
    "                d_str = ''\n",
    "                while i>0:\n",
    "                    d_str = d_str + document_str[i]\n",
    "                    d_str = d_str + ' '\n",
    "                    i = i-1\n",
    "                #print(d_str)\n",
    "                input_document.append(d_str)\n",
    "            num_step +=1\n",
    "    return input_document, target_summary, generated_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  reading train data line 0\n",
      "  reading train data line 10000\n",
      "  reading train data line 20000\n",
      "single_cell\n",
      "Reading Gen model parameters from /Users/zhangyiman/final project/gen_data_d/checkpoints/chitchat.model-5700\n",
      "generating num_step:  0\n",
      "  stands and is used _UNK _UNK \n",
      "  hours ahead _UNK is hours ahead and _UNK is hours ahead \n",
      "generating num_step:  1\n",
      "  open on on \n",
      "  click on modems tab \n",
      "generating num_step:  2\n",
      "  in asking it the same right the answer \n",
      "  by placing your question in the proper forum and not the _UNK one \n",
      "generating num_step:  3\n",
      "  women are more you need to need more information and free \n",
      "  those are just sitting around online you need to contact the texas vital statistics department \n",
      "generating num_step:  4\n",
      "  yahoo your blocker but either when will erase yahoo on yahoo \n",
      "  edit my info communications check mark allow yahoo contact via messenger \n",
      "generating num_step:  5\n",
      "  _UNK of god _UNK _UNK _UNK the _UNK _UNK the _UNK \n",
      "  _UNK of egypt during egypt _UNK age the _UNK was the man \n",
      "generating num_step:  6\n",
      "  poor old old very very old _UNK \n",
      "  trucks are pretty pimp these days especially my babys dodge ram \n",
      "generating num_step:  7\n",
      "  yahoo is carbon yahoo and are there there there you have the _UNK is you \n",
      "  email harvesting is big business everywhere and we all suffer from it you are no different \n",
      "generating num_step:  8\n",
      "  it easy you look and _UNK \n",
      "  it after you beat and cc it just backwards \n",
      "generating num_step:  9\n",
      "  go to yahoo click click on your yahoo and delete it \n",
      "  go to tools internet options delete cookies that should solve your problem \n",
      "generating num_step:  10\n",
      "  you have to be to have to be more people i know it is you know \n",
      "  you have to be in lve to know how beautiful and how precious your life is \n",
      "generating num_step:  11\n",
      "  why just first us one more more _UNK \n",
      "  should learn english first we do need any more indians over here taking our techie jobs \n",
      "generating num_step:  12\n",
      "  because god is a female of it \n",
      "  because hydrocortizone is a miracle cream \n",
      "generating num_step:  13\n",
      "  you have questions you got them and your email email \n",
      "  you have too much time to waste on the computer go outside and talk to people \n",
      "generating num_step:  14\n",
      "  start candles watchers \n",
      "  eat fresh ginger root \n",
      "generating num_step:  15\n",
      "  read the memory and the dining information you ask your question \n",
      "  read the guidelines you should put something else in your question title \n",
      "generating num_step:  16\n",
      "  _UNK camino is used for _UNK x is _UNK \n",
      "  _UNK number is speed length kinematic viscosity or length \n",
      "generating num_step:  17\n",
      "  _UNK question is what what what what \n",
      "  _UNK balls is what my uses \n",
      "generating num_step:  18\n",
      "  it the answer is the same of the answer is the the _UNK \n",
      "  it the path not he path and the answer is the one of least resistance \n",
      "generating num_step:  19\n",
      "  there are different one at the people are you are _UNK are you \n",
      "  there are some things in this world that we are better off not knowing \n",
      "generating num_step:  20\n",
      "  because it was the same of \n",
      "  because it is in the morning and im weeks pregnant not much else i can do \n",
      "generating num_step:  21\n",
      "  they can use practice \n",
      "  they can sell more _UNK \n",
      "generating num_step:  22\n",
      "  put them to turn to your own list you you tell you you help \n",
      "  then sell them to your _UNK why would i want to contact you \n",
      "generating num_step:  23\n",
      "  jews told all just _UNK _UNK and _UNK in _UNK \n",
      "  jews have _UNK african americans and other races have _UNK \n",
      "generating num_step:  24\n",
      "  wow you just ask to a more \n",
      "  apparently you know how to use it because you said i do thanks for the \n",
      "generating num_step:  25\n",
      "  they are are wrong right \n",
      "  they are calling people happy \n",
      "generating num_step:  26\n",
      "  click on and then it can can then then then \n",
      "  double click it you can also and then choose \n",
      "generating num_step:  27\n",
      "  _UNK and in the _UNK and the _UNK of the _UNK and _UNK \n",
      "  _UNK and in the united states and the indian _UNK of technology in india \n",
      "generating num_step:  28\n",
      "  at the same reason not god that god was god \n",
      "  for the same reason that caviar does taste like fish \n",
      "generating num_step:  29\n",
      "  that they are _UNK \n",
      "  that they are color blind \n",
      "generating num_step:  30\n",
      "  same of the same of the meaning and _UNK \n",
      "  age of the tree the rings inside per year hurbs dont know \n",
      "generating num_step:  31\n",
      "  yes it works with a yahoo \n",
      "  no _UNK type it in on yahoo or google or msn \n",
      "generating num_step:  32\n",
      "  i am never get something to very very job \n",
      "  she probably didnt feel confident enough to meet you \n",
      "generating num_step:  33\n",
      "  why the same is you have to be the more \n",
      "  why in the _UNK would you want to have your tongue pierced \n",
      "generating num_step:  34\n",
      "  _UNK is yahoo in yahoo and yahoo \n",
      "  _UNK is here _UNK delete it that all \n",
      "generating num_step:  35\n",
      "  multiply by divide by x \n",
      "  multiply both sides by x \n",
      "generating num_step:  36\n",
      "  well i know me to me \n",
      "  good question i do know what to smell it \n",
      "generating num_step:  37\n",
      "  because they are _UNK and to eat and to get them and _UNK \n",
      "  because they are for away and its nice to get them \n",
      "generating num_step:  38\n",
      "  it a web and start and start and start your new link \n",
      "  an _UNK triangle pointing up and another pointing down right on top of it \n",
      "generating num_step:  39\n",
      "  why would you want to go \n",
      "  why would you want to hunt or capture \n",
      "generating num_step:  40\n",
      "  you are need to be what you have a little fat \n",
      "  you are going to be alone on thanksgiving \n",
      "generating num_step:  41\n",
      "  try email themes you have your computer you need it a computer \n",
      "  try yahoo chat to make friends there i sure there a belgium chat room \n",
      "generating num_step:  42\n",
      "  i think i would would have people just a people i be a own \n",
      "  i wouldnt say we were lucky but we did see one ring a bell \n",
      "generating num_step:  43\n",
      "  i think it _UNK to a _UNK and what what what \n",
      "  i think it _UNK it fits the word you are looking for \n",
      "generating num_step:  44\n",
      "  throw the same of the same same of the same question \n",
      "  studies the changing responses of the general reading public over time \n",
      "generating num_step:  45\n",
      "  use starters a doctor you a lot a lot \n",
      "  use exfoliant once a week it helps a lot \n",
      "generating num_step:  46\n",
      "  _UNK they do think it \n",
      "  so that they do grow up to be a parasite \n",
      "generating num_step:  47\n",
      "  ham tea hair works and soft stain stain stain drink drink \n",
      "  tea tree oil will help prevent and cure lice infestation drops rubbed into hair daily \n",
      "generating num_step:  48\n",
      "  points information answer for asking a question for your question for what for more info \n",
      "  points best answer points for a question point for just showing up at y a points \n",
      "generating num_step:  49\n",
      "  in one one this it is a best way \n",
      "  its only in your head man god is it friday yet \n"
     ]
    }
   ],
   "source": [
    "list1,list2,list3 = decode(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Flag = True # Flag = true: write a csv file Flag = False, don't write\n",
    "#Flag = False\n",
    "#decode_num_step = 50000\n",
    "#generated_data_for_D(Flag,decode_num_step)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
